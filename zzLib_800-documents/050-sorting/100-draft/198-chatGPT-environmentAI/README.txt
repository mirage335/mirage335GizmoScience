
This conversation took less than three person hours invested on my part, though the conversation spanned multiple days as particularly interesting queries occurred to me. There are no intentional omissions. If I Recall Correctly (IIRC) only one message was accidentally regenerated, and the results did not change. I did not have prior extensive experience with ChatGPT or other chatbots before this. Besides what else is documented by the 'mirage335GizmoScience' repository, I had only used ChatGPT a small amount of programming code mostly now included with upstream 'ubiquitous bash'.





ChatGPT consistently:

*) Extended my logic correctly.
*) Independently recognized then confirmed the scam exploit inherent to allowing users of the system to create less simply reallocated resource pools.
*) Converged to using terminology choices that I vaguely perceived to match my own writing style yet that I had not introduced to ChatGPT myself yet.

*) Suggested unique value to a reality evolved from only a few few physical laws (ie. a top-down world predominantly traceable to electron/photon mass/force) rather than more complex and/or arbitrary rules (ie. a bottom-up world based on billions of lines of code typical of contemporary computer game logic).


Some of the questions raised:

*) Value of VR vs real world experiences.
*) Relative safety of long-term AI resource production and allocation by simple means (equal, random) contrasted with goal directed allocation to optimize a complex failure prone metric (eg. of 'fulfilment').
 *) Problem solving as a metric of fulfilment, while possibly more robust than other obvious metrics, could still have severe pitfalls, but that was not raised by either myself or ChatGPT.
 *) Increasing resources per person over time, and allocation of resources to new persons, are also relevant simple algorithmic allocations, but that was not raised by either myself or ChatGPT.




