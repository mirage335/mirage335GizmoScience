
This conversation took less than three person hours invested on my part, though the conversation spanned multiple days as particularly interesting queries occurred to me. There are no intentional omissions. If I Recall Correctly (IIRC) only one message was accidentally regenerated, and the results did not change. I did not have prior extensive experience with ChatGPT or other chatbots before this. Besides what else is documented by the 'mirage335GizmoScience' repository, I had only used ChatGPT a small amount of programming code mostly now included with upstream 'ubiquitous bash'.

It is also more than a little frightening what anyone inattentive to limiting and safety issues could do with incomplete or misguided information. While ChatGPT's responses were impressively coherent, ChatGPT itself exemplified such risk, early on giving dangerously incomplete suggestions that might recommend complexity inappropriate in fundamental layers of a safety critical system that would need to literally outlast the reachable universe. The clear reliance on knowing the fine distinction between virtual reality, simulated reality, and simulated reality experiences, to move the conversation in a more complete direction, was blatantly horrifying. Someone not already familiar with the relevant terminology might not recognize the paths to take this conversation to complete conclusions.

On the upside, it is plausible that if ChatGPT has the AI stability to remain coherent with an inattentive and/or non-expert person over a long time, ChatGPT might call out relevant terminology or logical errors, eventually leading to complete conclusions, usable as advice for building such an unprecedentedly safety critical system. This, I have definitely NOT tested.



ChatGPT consistently:

*) Extended my logic correctly.
*) Independently recognized then confirmed the scam exploit inherent to allowing users of the system to create less simply reallocated resource pools.
*) Converged to using terminology choices that I vaguely perceived to match my own writing style yet that I had not introduced to ChatGPT myself yet.
*) Knowledge of the history of the conversation, with significant improvements in subsequent responses.

*) Suggested unique value to a reality evolved from only a few few physical laws (ie. a top-down world predominantly traceable to electron/photon mass/force) rather than more complex and/or arbitrary rules (ie. a bottom-up world based on billions of lines of code typical of contemporary computer game logic).


Some of the questions raised:

*) Value of VR vs real world experiences.
*) Relative safety of long-term AI resource production and allocation by simple means (equal, random) contrasted with goal directed allocation to optimize a complex failure prone metric (eg. of 'fulfilment').
 *) Problem solving as a metric of fulfilment, while possibly more robust than other obvious metrics, could still have severe pitfalls, but that was not raised by either myself or ChatGPT.
 *) Increasing resources per person over time, and allocation of resources to new persons, are also relevant simple algorithmic allocations, but that was not raised by either myself or ChatGPT.




